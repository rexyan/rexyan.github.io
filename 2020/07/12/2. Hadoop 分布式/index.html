<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico">
  <link rel="mask-icon" href="/favicon.ico" color="#222">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.loli.net/css?family=Noto Serif SC:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"rexyan.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"top","display":"hide","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"buttons","active":null,"storage":true,"lazyload":true,"nav":{"disqus":{"text":"Load Disqus","order":-1}}},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":3,"unescape":false,"preload":false},"motion":{"enable":false,"async":true,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="搭建 Hadoop 分布式准备机器克隆两个虚拟机，修改主机名和网络，分别如下 123hadoop10  192.168.1.10hadoop11  192.168.1.11hadoop12  192.168.1.12 因为是克隆的虚拟机，所以 java 环境，rexyan 用户在伪分布式都有了，所以这些步骤就不重复了。hadoop 因为之前进行了配置，所以会重装。三个虚拟机，要求每个内存至少 4G">
<meta name="keywords" content="Hadoop">
<meta property="og:type" content="article">
<meta property="og:title" content="2. Hadoop 分布式">
<meta property="og:url" content="https://rexyan.github.io/2020/07/12/2. Hadoop 分布式/index.html">
<meta property="og:site_name" content="星尘">
<meta property="og:description" content="搭建 Hadoop 分布式准备机器克隆两个虚拟机，修改主机名和网络，分别如下 123hadoop10  192.168.1.10hadoop11  192.168.1.11hadoop12  192.168.1.12 因为是克隆的虚拟机，所以 java 环境，rexyan 用户在伪分布式都有了，所以这些步骤就不重复了。hadoop 因为之前进行了配置，所以会重装。三个虚拟机，要求每个内存至少 4G">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjI4KF7gl0*JuBDmxRAeohR3NXgm0aGIU*H0l66rirgzgG*Avup4z1W77wcMufsJMcA!!/mnull&bo=MAJDAjACQwIDCSw!&rf=photolist&t=5/r/_yake_qzoneimgout.png">
<meta property="og:image" content="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjFYKEcXZa7c*.6uTAevtfo.aKnVpWc.fv7HnXX3vpSzE7VS4oKpyCAsGgP6FesSnXA!!/mnull&bo=hAmAAnAKvgIDCeU!&rf=photolist&t=5/r/_yake_qzoneimgout.png">
<meta property="og:image" content="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjD.2LprpEprgOYnglxn.I7lAegrJIGjGhL*qT2hZrXLMxphwZV*9YWFzwdN9zIcLJg!!/mnull&bo=PAxABkQMRAYDCVA!&rf=photolist&t=5/r/_yake_qzoneimgout.png">
<meta property="og:image" content="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjMwk3KKfhO8ox2qB7acozE0torElBOyjHuazxvDs3w5GiAFhPPS9REqgw2fnF3bx.Q!!/mnull&bo=lgkcApYJHAIDCSw!&rf=photolist&t=5/r/_yake_qzoneimgout.png">
<meta property="og:image" content="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjPR0N4LRWX54B9sjXItl31ZvBArFAlnVpUgHX7Fn0IBySnPyFXr.d1uOj60EUmxkzA!!/mnull&bo=OgaAAlIJvgMDCXQ!&rf=photolist&t=5/r/_yake_qzoneimgout.png">
<meta property="og:image" content="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjFr3bPrt8kS0jpz.Z69puYo*qEAwkOzWCnzmkY4U8qJo.z9pO126RKK2eqKVYlH8Xg!!/mnull&bo=mgeAAgoNSgQDCXo!&rf=photolist&t=5/r/_yake_qzoneimgout.png">
<meta property="og:image" content="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjCVM0Polf8KE0Gu9U0gbUA7I0V.IPz9R7T7EKqeTWfLVmAfZHcdrr8sr70YJQVnMhw!!/mnull&bo=4QWAAqQKhgQDCWY!&rf=photolist&t=5/r/_yake_qzoneimgout.png">
<meta property="og:image" content="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjCEN5xtuwWIM5fQVVYa.LNsdzc3at20ViyFADWYlTs6CsQJvdQNdQUPgZG.mys32iQ!!/mnull&bo=zgaAAsIK9AMDCVk!&rf=photolist&t=5/r/_yake_qzoneimgout.png">
<meta property="og:image" content="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjMsFnRcfEPxRebd.Bo*YGvccd.3KYOSYD1gDbCwNa4EsK7Ziy9bzPbzFcocw7ehUHA!!/mnull&bo=EwmAAnwLKgMDCeo!&rf=photolist&t=5/r/_yake_qzoneimgout.png">
<meta property="og:image" content="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjFyj6sAwWzJiBcm93hUmPQuq9DBSjhpjmuq6QnNNVZiXicKBMcSyJ8HQvQQtZ*gJcg!!/mnull&bo=FAiAAs4KWAMDCS0!&rf=photolist&t=5/r/_yake_qzoneimgout.png">
<meta property="og:image" content="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjOw8dRT6BypnSE5LGpbT*LVCx1zXldEQptS2BtivuMrOcNu45sWRYuViEQnoa.5WKg!!/mnull&bo=SAiAAhgN9AMDCQw!&rf=photolist&t=5/r/_yake_qzoneimgout.png">
<meta property="og:image" content="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjElR8FRR*2GbQu9rp8cRzUpSPe82vOf9OcWKl9*9v3rwaZ9OdEE1pF5OwuQSRokwrA!!/mnull&bo=AQaAAvwMaAUDCTQ!&rf=photolist&t=5/r/_yake_qzoneimgout.png">
<meta property="og:updated_time" content="2025-10-31T03:20:39.383Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="2. Hadoop 分布式">
<meta name="twitter:description" content="搭建 Hadoop 分布式准备机器克隆两个虚拟机，修改主机名和网络，分别如下 123hadoop10  192.168.1.10hadoop11  192.168.1.11hadoop12  192.168.1.12 因为是克隆的虚拟机，所以 java 环境，rexyan 用户在伪分布式都有了，所以这些步骤就不重复了。hadoop 因为之前进行了配置，所以会重装。三个虚拟机，要求每个内存至少 4G">
<meta name="twitter:image" content="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjI4KF7gl0*JuBDmxRAeohR3NXgm0aGIU*H0l66rirgzgG*Avup4z1W77wcMufsJMcA!!/mnull&bo=MAJDAjACQwIDCSw!&rf=photolist&t=5/r/_yake_qzoneimgout.png">

<link rel="canonical" href="https://rexyan.github.io/2020/07/12/2. Hadoop 分布式/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>2. Hadoop 分布式 | 星尘</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

  
  <link rel="stylesheet" href="https://cdn.staticfile.org/lxgw-wenkai-screen-webfont/1.6.0/lxgwwenkaiscreen.css" />
  <!-- 自定义为霞鹜文楷字体 -->
  <style>
	  body,div.post-body,h1,h2,h3,h4 {
		font-family: "LXGW WenKai Screen", sans-serif;
		font-size: 104%;
	  }
  </style>
  
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">星尘</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-读书">

    <a href="/books/" rel="section"><i class="address-book fa-fw"></i>读书</a>

  </li>
        <li class="menu-item menu-item-瞎扯">

    <a href="/crap/" rel="section"><i class="crap fa-fw"></i>瞎扯</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



<script src="https://cdn.jsdelivr.net/npm/echarts@4.8.0/dist/echarts.min.js"></script>

<meta name="referrer" content="never">




  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://rexyan.github.io/2020/07/12/2. Hadoop 分布式/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://raw.githubusercontent.com/rexyan/warehouse/master/20230809141242.jpg">
      <meta itemprop="name" content="Rex">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="星尘">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          2. Hadoop 分布式
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-12 23:41:57" itemprop="dateCreated datePublished" datetime="2020-07-12T23:41:57+00:00">2020-07-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-10-31 03:20:39" itemprop="dateModified" datetime="2025-10-31T03:20:39+00:00">2025-10-31</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java-大数据进阶/" itemprop="url" rel="index"><span itemprop="name">Java 大数据进阶</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h3 id="搭建-Hadoop-分布式"><a href="#搭建-Hadoop-分布式" class="headerlink" title="搭建 Hadoop 分布式"></a>搭建 Hadoop 分布式</h3><h4 id="准备机器"><a href="#准备机器" class="headerlink" title="准备机器"></a>准备机器</h4><p>克隆两个虚拟机，修改主机名和网络，分别如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop10  192.168.1.10</span><br><span class="line">hadoop11  192.168.1.11</span><br><span class="line">hadoop12  192.168.1.12</span><br></pre></td></tr></table></figure>
<p>因为是克隆的虚拟机，所以 java 环境，rexyan 用户在伪分布式都有了，所以这些步骤就不重复了。hadoop 因为之前进行了配置，所以会重装。三个虚拟机，要求每个内存至少 4G，且都选择了时区和进行时间的同步，</p>
<p><img src="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjI4KF7gl0*JuBDmxRAeohR3NXgm0aGIU*H0l66rirgzgG*Avup4z1W77wcMufsJMcA!!/mnull&amp;bo=MAJDAjACQwIDCSw!&amp;rf=photolist&amp;t=5/r/_yake_qzoneimgout.png" alt></p>
<p>因为台机器会互相拷贝和传输文件，所以需要开启免密登录，这里以 192.168.1.10 为主要的机器，他会往 192.168.1.11 和 192.168.1.12 拷贝文件，所以配置 192.168.1.10 在 192.168.1.11 和 192.168.1.12 的免密登录。在 192.168.1.10 上执行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa  # 生成 192.168.1.10 的密钥信息</span><br><span class="line">ssh-copy-id hadoop10  # 将密钥信息拷贝到 自己，实现免密登录</span><br><span class="line">ssh-copy-id hadoop11  # 将密钥信息拷贝到 hadoop11，实现免密登录</span><br><span class="line">ssh-copy-id hadoop12  # 将密钥信息拷贝到 hadoop12，实现免密登录</span><br><span class="line"></span><br><span class="line">ssh hadoop10  # 测试是否能免密登上 自己</span><br><span class="line">ssh hadoop11  # 测试是否能免密登上 hadoop11</span><br><span class="line">ssh hadoop12  # 测试是否能免密登上 hadoop12</span><br></pre></td></tr></table></figure>
<h4 id="编写集群文件分发脚本"><a href="#编写集群文件分发脚本" class="headerlink" title="编写集群文件分发脚本"></a>编写集群文件分发脚本</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>!/bin/bash</span><br><span class="line"><span class="meta">#</span>校验参数是否合法</span><br><span class="line"><span class="meta">if(($</span>#==0))</span><br><span class="line">then</span><br><span class="line">	echo 请输入要分发的文件!</span><br><span class="line">	exit;</span><br><span class="line">fi</span><br><span class="line"><span class="meta">#</span>获取分发文件的绝对路径</span><br><span class="line">dirpath=$(cd `dirname $1`; pwd -P)</span><br><span class="line">filename=`basename $1`</span><br><span class="line"></span><br><span class="line">echo 要分发的文件的路径是:$dirpath/$filename</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>循环执行rsync分发文件到集群的每条机器</span><br><span class="line">for((i=10;i&lt;=12;i++))</span><br><span class="line">do</span><br><span class="line">	echo ---------------------hadoop$i---------------------</span><br><span class="line">	rsync -rvlt $dirpath/$filename  rexyan@hadoop$i:$dirpath</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<p>例如，需要在 hadoop10  tmp 目录下创建 test 文件，并将文件分发到 hadoop11，hadoop12 中的 tmp 目录下</p>
<p><img src="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjFYKEcXZa7c*.6uTAevtfo.aKnVpWc.fv7HnXX3vpSzE7VS4oKpyCAsGgP6FesSnXA!!/mnull&amp;bo=hAmAAnAKvgIDCeU!&amp;rf=photolist&amp;t=5/r/_yake_qzoneimgout.png" alt></p>
<p>这样就能将 10 下面的 /tmp/test 文件拷贝到 11 和 12 下面</p>
<h4 id="规划集群"><a href="#规划集群" class="headerlink" title="规划集群"></a>规划集群</h4><p>重新规划集群角色如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hadoop10					hadoop11					hadoop12</span><br><span class="line"></span><br><span class="line">DataNode					DataNode					DataNode</span><br><span class="line">NodeManager   		NodeManager   		NodeManager</span><br><span class="line">NameNode					ResourceManager		SecondaryNamenode</span><br></pre></td></tr></table></figure>
<h4 id="安装-Hadoop"><a href="#安装-Hadoop" class="headerlink" title="安装 Hadoop"></a>安装 Hadoop</h4><p>解压上传好的 hadoop 到 /opt/module/</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf /opt/soft/hadoop-2.7.2.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>
<p>配置 core-site.xml 将 hdfs 配置成为分布式，因为规划的是在 10上启动 namenode，所以配置文件中 value为 10的地址</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop10:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/data/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>在 hdfs-site.xml 中配置 2NN（SecondaryNamenode），按照规划 2NN 是配置到 hadoop12 机器上的，所以 value 要写 hadoop12 的地址。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop12:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>配置 yarn-site.xml，按照规划 ResourceManager 运行在 hadoop11，所以 value 指定 ResourceManager 运行的机器为 hadoop11</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 获取数据的方式 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop11<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>将  mapred-site.xml.template  文件复制另一份为 mapred-site.xml，并在其中设置 mapreduce 的运行方式为 yarn</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>利用集群分发脚本，将配置好的 hadoop 文件分发到其他机器</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash xsync /opt/module/hadoop-2.7.2/</span><br></pre></td></tr></table></figure>
<p>分别配置三台机器的环境变量，将 hadoop 加入到坏境变量中，如果没有配置 java 的环境变量，也需要进行配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">JAVA_HOME=/opt/module/jdk1.8.0_121</span><br><span class="line">HADOOP_HOME=/opt/module/hadoop-2.7.2</span><br><span class="line">PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure>
<h4 id="使用-SSH-执行在远端执行命令及问题"><a href="#使用-SSH-执行在远端执行命令及问题" class="headerlink" title="使用 SSH 执行在远端执行命令及问题"></a>使用 SSH 执行在远端执行命令及问题</h4><p>在 10 机器上，执行 ssh hadoop11 jps，提示 找不到 jps 命令，但是 hadoop11 的确已经配置了 java 的环境变量了的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[rexyan@hadoop10 ~]$ ssh hadoop11 jps</span><br></pre></td></tr></table></figure>
<p>为什么会发生这种现象呢，因为 ssh 一台机器后马上执行某命令，这样的没有交互的登录方式叫做 Non-Login shell，这种 Non-Login shell 执行登录脚本的顺序是</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. ~/.bashrc</span><br><span class="line">2. /etc/bashrc</span><br><span class="line">3. /etc/profile.d/目录下的脚本</span><br></pre></td></tr></table></figure>
<p>因为我们的环境变量是添加到 /etc/profile 下面的，没有在 Non-Login shell  的加载顺序中，所以提示找不到 jps 命令。解决方法就是在 /etc/bashrc 中 source /etc/profile。这样就算是以 Non-Login shell  的方式执行命令，那么也能找到 /etc/profile 下设置的环境变量，也就能找到 jps 命令。</p>
<p>所以我们需要在所有机器的 /etc/bashrc 中添加 source /etc/profile</p>
<h4 id="编写集群执行同一命令脚本"><a href="#编写集群执行同一命令脚本" class="headerlink" title="编写集群执行同一命令脚本"></a>编写集群执行同一命令脚本</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>!/bin/bash</span><br><span class="line"><span class="meta">#</span>在集群的所有机器上批量执行同一条命令</span><br><span class="line"><span class="meta">if(($</span>#==0))</span><br><span class="line">then</span><br><span class="line">	echo 请输入您要操作的命令！</span><br><span class="line">	exit</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">echo 要执行的命令是$*</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>循环执行此命令</span><br><span class="line">for((i=10;i&lt;=12;i++))</span><br><span class="line">do</span><br><span class="line">	echo ---------------------hadoop$i-----------------</span><br><span class="line">	ssh hadoop$i $*</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<p>例如，在所有机器上执行 ifconfig，只需执行 bash xcall ifconfig 即可</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash xcall ifconfig</span><br></pre></td></tr></table></figure>
<p><img src="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjD.2LprpEprgOYnglxn.I7lAegrJIGjGhL*qT2hZrXLMxphwZV*9YWFzwdN9zIcLJg!!/mnull&amp;bo=PAxABkQMRAYDCVA!&amp;rf=photolist&amp;t=5/r/_yake_qzoneimgout.png" alt></p>
<h4 id="启动-HDFS"><a href="#启动-HDFS" class="headerlink" title="启动 HDFS"></a>启动 HDFS</h4><p>在启动 hdfs 之前，我们需要对 namenode 进行格式化，因为 namenode 是在 hadoop10 机器上的，所以需要在 hadoop10 机器上执行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop namenode -format</span><br></pre></td></tr></table></figure>
<p>在 hadoop10 上启动 namenode</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon.sh start  namenode</span><br></pre></td></tr></table></figure>
<p>在 hadoop10，hadoop11，hadoop12 上启动 datanode</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash xcall hadoop-daemon.sh start datanode</span><br></pre></td></tr></table></figure>
<p>在 hadoop12 上启动 SecondaryNamenode</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon.sh start secondarynamenode</span><br></pre></td></tr></table></figure>
<p>查看各机器启动状态</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash xcall jps</span><br></pre></td></tr></table></figure>
<p><img src="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjMwk3KKfhO8ox2qB7acozE0torElBOyjHuazxvDs3w5GiAFhPPS9REqgw2fnF3bx.Q!!/mnull&amp;bo=lgkcApYJHAIDCSw!&amp;rf=photolist&amp;t=5/r/_yake_qzoneimgout.png" alt></p>
<p>访问 web 页面看是成功，因为 namenode 是在 10 上的，所以访问 <a href="http://192.168.1.10:50070/" target="_blank" rel="noopener">http://192.168.1.10:50070/</a> 即可</p>
<p><img src="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjPR0N4LRWX54B9sjXItl31ZvBArFAlnVpUgHX7Fn0IBySnPyFXr.d1uOj60EUmxkzA!!/mnull&amp;bo=OgaAAlIJvgMDCXQ!&amp;rf=photolist&amp;t=5/r/_yake_qzoneimgout.png" alt></p>
<h4 id="启动-YARN"><a href="#启动-YARN" class="headerlink" title="启动 YARN"></a>启动 YARN</h4><p>ResourceManager 是规划在 hadoop11 机器上的，所以在 hadoop11 启动 ResourceManager</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn-daemon.sh  start resourcemanager</span><br></pre></td></tr></table></figure>
<p>在 hadoop10，hadoop11，hadoop12 上启动 nodemanager</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash xcall yarn-daemon.sh  start nodemanager</span><br></pre></td></tr></table></figure>
<p>访问 web 页面看是否存在文件，resourcemanager 是在 hadoop11 上启动的，所以访问 <a href="http://192.168.1.11:8088/cluster" target="_blank" rel="noopener">http://192.168.1.11:8088/cluster</a> ，可以看到三个 nodemanager 也启动了。</p>
<p><img src="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjFr3bPrt8kS0jpz.Z69puYo*qEAwkOzWCnzmkY4U8qJo.z9pO126RKK2eqKVYlH8Xg!!/mnull&amp;bo=mgeAAgoNSgQDCXo!&amp;rf=photolist&amp;t=5/r/_yake_qzoneimgout.png" alt></p>
<h4 id="测试集群"><a href="#测试集群" class="headerlink" title="测试集群"></a>测试集群</h4><p>创建一个文件夹，上传一个文件到创建好的 hdfs 文件夹中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir /wcinput3</span><br><span class="line">hadoop fs -put hello2 /wcinput3</span><br></pre></td></tr></table></figure>
<p>测试 yarn，并查询运行结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar hadoop-mapreduce-examples-2.7.2.jar wordcount /wcinput3 /wcoutput3</span><br><span class="line">hadoop fs -cat /wcoutput3/part-r-00000</span><br></pre></td></tr></table></figure>
<h4 id="群启脚本"><a href="#群启脚本" class="headerlink" title="群启脚本"></a>群启脚本</h4><p>在 /opt/module/hadoop-2.7.2/sbin 目录下有很多启动和停止的脚本，可以不用一个一个去执行和停止 hdfs 进程和 yarn 进程，群启脚本可以批量启动和停止。</p>
<p><img src="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjCVM0Polf8KE0Gu9U0gbUA7I0V.IPz9R7T7EKqeTWfLVmAfZHcdrr8sr70YJQVnMhw!!/mnull&amp;bo=4QWAAqQKhgQDCWY!&amp;rf=photolist&amp;t=5/r/_yake_qzoneimgout.png" alt></p>
<p>群起脚本的原理是获取集群中所有的节点的主机名，默认读取当前机器 HADOOP_HOME/etc/hadoop/slaves，获取集群中所有的节点的主机名。循环执行 ssh 主机名 hadoop-daemon.sh start xxx 所以需要保证当前机器（需要执行群启的机器）到其他节点，已经配置了ssh免密登录，保证集群中所有机器当前用户的家目录/.bashrc中，已经配置 source /etc/profile。</p>
<p>注意⚠️：start-all.sh 时，其实分别调用了start-dfs.sh 和 start-yarn.sh，start-dfs.sh 可以在集群的任意一台机器使用！可以启动 HDFS 中的所有进程。start-yarn.sh 在集群的非RM所在的机器使用，不会启动resourcemanager, stop-yarn.sh 也是一样的，不会停止 resourcemanager 。所以，建议是配置 RM 所在机器到其他机器的 SSH 免密登录，都在 RM 所在的机器执行群起和群停脚本 xsync 和 xcall 只放在 RM 所在的机器即可（上面我们不是这样的，上面我们的规划是 11 是 RM 所在的机器，但是 10 配置了到所有机器的免密登录，xsync 和 xcall 脚本）</p>
<p>在 10 上配置 slaves 文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop10</span><br><span class="line">hadoop11</span><br><span class="line">hadoop12</span><br></pre></td></tr></table></figure>
<p>停止所有服务，然后查看状态</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">stop-all.sh </span><br><span class="line">cd ~</span><br><span class="line">bash xcall jps</span><br></pre></td></tr></table></figure>
<p><img src="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjCEN5xtuwWIM5fQVVYa.LNsdzc3at20ViyFADWYlTs6CsQJvdQNdQUPgZG.mys32iQ!!/mnull&amp;bo=zgaAAsIK9AMDCVk!&amp;rf=photolist&amp;t=5/r/_yake_qzoneimgout.png" alt></p>
<p>群启 hdfs </p>
<p><img src="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjMsFnRcfEPxRebd.Bo*YGvccd.3KYOSYD1gDbCwNa4EsK7Ziy9bzPbzFcocw7ehUHA!!/mnull&amp;bo=EwmAAnwLKgMDCeo!&amp;rf=photolist&amp;t=5/r/_yake_qzoneimgout.png" alt></p>
<p>群启 yarn</p>
<p><img src="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjFyj6sAwWzJiBcm93hUmPQuq9DBSjhpjmuq6QnNNVZiXicKBMcSyJ8HQvQQtZ*gJcg!!/mnull&amp;bo=FAiAAs4KWAMDCS0!&amp;rf=photolist&amp;t=5/r/_yake_qzoneimgout.png" alt></p>
<p>单独在 11 上启动 resourcemanager</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn-daemon.sh start resourcemanager</span><br></pre></td></tr></table></figure>
<h4 id="日志服务"><a href="#日志服务" class="headerlink" title="日志服务"></a>日志服务</h4><p>为了方便查看日志，需要为 10 机器配置日志收集服务，修改 mapred-site.xml, 添加如下配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 机器 10 配置jobhistory服务 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop10:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 将收集的日志提供 web 访问 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop10:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--第三方框架使用yarn计算的日志聚集功能，例如 spark 等框架 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span>					    </span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>http://hadoop10:19888/jobhistory/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 日志保留时间设置7天 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>在 10 机器上将脚本进行分发到其他机器，然后停止并重启集群</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bash xsync /opt/module/hadoop-2.7.2/etc/hadoop/  # 注意这里只同步了配置文件的目录</span><br><span class="line">stop-all.sh </span><br><span class="line">start-all.sh</span><br></pre></td></tr></table></figure>
<p>在 12 上重启 resourcemanager</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn-daemon.sh stop resourcemanager</span><br></pre></td></tr></table></figure>
<p>在 10 上启动日志服务</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure>
<p>再次执行任务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar hadoop-mapreduce-examples-2.7.2.jar wordcount /wcinput3 /wcoutput4</span><br></pre></td></tr></table></figure>
<p>通过 yarn 的 web 页面查看日志</p>
<p><img src="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjOw8dRT6BypnSE5LGpbT*LVCx1zXldEQptS2BtivuMrOcNu45sWRYuViEQnoa.5WKg!!/mnull&amp;bo=SAiAAhgN9AMDCQw!&amp;rf=photolist&amp;t=5/r/_yake_qzoneimgout.png" alt></p>
<p><img src="https://r.photo.store.qq.com/psc?/V12EvAd609VbnF/ChQ0KIcA.iub3F93BayOjElR8FRR*2GbQu9rp8cRzUpSPe82vOf9OcWKl9*9v3rwaZ9OdEE1pF5OwuQSRokwrA!!/mnull&amp;bo=AQaAAvwMaAUDCTQ!&amp;rf=photolist&amp;t=5/r/_yake_qzoneimgout.png" alt></p>

    </div>

    
    
    

      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/Hadoop/" rel="tag"><i class="fa fa-tag"></i> Hadoop</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/07/12/1. Hadoop 伪分布式/" rel="prev" title="1. Hadoop 伪分布式">
      <i class="fa fa-chevron-left"></i> 1. Hadoop 伪分布式
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/07/22/3. HDFS/" rel="next" title="3. HDSF">
      3. HDSF <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#搭建-Hadoop-分布式"><span class="nav-number">1.</span> <span class="nav-text">搭建 Hadoop 分布式</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#准备机器"><span class="nav-number">1.1.</span> <span class="nav-text">准备机器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#编写集群文件分发脚本"><span class="nav-number">1.2.</span> <span class="nav-text">编写集群文件分发脚本</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#规划集群"><span class="nav-number">1.3.</span> <span class="nav-text">规划集群</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#安装-Hadoop"><span class="nav-number">1.4.</span> <span class="nav-text">安装 Hadoop</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#使用-SSH-执行在远端执行命令及问题"><span class="nav-number">1.5.</span> <span class="nav-text">使用 SSH 执行在远端执行命令及问题</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#编写集群执行同一命令脚本"><span class="nav-number">1.6.</span> <span class="nav-text">编写集群执行同一命令脚本</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#启动-HDFS"><span class="nav-number">1.7.</span> <span class="nav-text">启动 HDFS</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#启动-YARN"><span class="nav-number">1.8.</span> <span class="nav-text">启动 YARN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#测试集群"><span class="nav-number">1.9.</span> <span class="nav-text">测试集群</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#群启脚本"><span class="nav-number">1.10.</span> <span class="nav-text">群启脚本</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#日志服务"><span class="nav-number">1.11.</span> <span class="nav-text">日志服务</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Rex"
      src="https://raw.githubusercontent.com/rexyan/warehouse/master/20230809141242.jpg">
  <p class="site-author-name" itemprop="name">Rex</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">446</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">20</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">183</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2017 – 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa-hand-o-right"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Rex</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
<script src="/js/utils.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>



  




  <script src="/js/local-search.js"></script>












  

  

</body>
</html>
